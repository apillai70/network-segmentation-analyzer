# ðŸ“Š Program Outputs Guide

Complete guide to all files and artifacts generated by the Network Segmentation Analyzer

---

## Output Directory Structure

```
network-segmentation-analyzer/
â”‚
â”œâ”€â”€ outputs_final/                      # Main output directory
â”‚   â”œâ”€â”€ network_analysis.db            # SQLite database (or use PostgreSQL)
â”‚   â”œâ”€â”€ incremental_topology.json      # Current topology state
â”‚   â”œâ”€â”€ persistent_data/               # JSON persistence (if PostgreSQL unavailable)
â”‚   â”‚   â”œâ”€â”€ applications.json
â”‚   â”‚   â”œâ”€â”€ flows.json
â”‚   â”‚   â””â”€â”€ topology.json
â”‚   â””â”€â”€ backups/                       # Automatic backups
â”‚
â”œâ”€â”€ visualizations/                    # Static visualizations
â”‚   â”œâ”€â”€ network_graph_d3.html         # D3.js interactive network graph
â”‚   â”œâ”€â”€ segmentation_mermaid.html     # Mermaid segmentation diagram
â”‚   â””â”€â”€ lucidchart_export.csv         # Lucidchart import file
â”‚
â”œâ”€â”€ models/                            # Trained models
â”‚   â”œâ”€â”€ incremental/                   # Incremental learning checkpoints
â”‚   â”‚   â”œâ”€â”€ processed_files.json      # List of processed files
â”‚   â”‚   â”œâ”€â”€ gnn_checkpoint.pt         # GNN model weights (if using PyTorch)
â”‚   â”‚   â”œâ”€â”€ rnn_checkpoint.pt
â”‚   â”‚   â”œâ”€â”€ cnn_checkpoint.pt
â”‚   â”‚   â””â”€â”€ attention_checkpoint.pt
â”‚   â””â”€â”€ ensemble/                      # Ensemble model checkpoints
â”‚       â”œâ”€â”€ gnn_YYYYMMDD_HHMMSS.pkl
â”‚       â”œâ”€â”€ rnn_YYYYMMDD_HHMMSS.pkl
â”‚       â”œâ”€â”€ cnn_YYYYMMDD_HHMMSS.pkl
â”‚       â”œâ”€â”€ attention_YYYYMMDD_HHMMSS.pkl
â”‚       â””â”€â”€ meta_YYYYMMDD_HHMMSS.pkl
â”‚
â”œâ”€â”€ logs/                              # Execution logs
â”‚   â”œâ”€â”€ system_startup_YYYYMMDD_HHMMSS.log
â”‚   â”œâ”€â”€ incremental_YYYYMMDD_HHMMSS.log
â”‚   â””â”€â”€ web_app_YYYYMMDD_HHMMSS.log
â”‚
â””â”€â”€ data/                              # Data directories
    â”œâ”€â”€ input/                         # Input flow files
    â”‚   â””â”€â”€ App_Code_*.csv            # Application flow files (generated or actual)
    â””â”€â”€ output/                        # Intermediate processing files
```

---

## Detailed Output Files

### 1. Database Outputs

#### **network_analysis.db** (SQLite) or **PostgreSQL Database**
- **Location**: `outputs_final/network_analysis.db`
- **Format**: SQLite database or PostgreSQL
- **Purpose**: Primary data storage
- **Tables**:
  - `applications` - Application metadata
  - `flows` - Network flow records
  - `nodes` - IP addresses with features
  - `services` - IP:Port combinations
  - `segmentation_zones` - Security zone definitions
  - `node_zone_assignments` - Node-to-zone mappings
  - `model_metadata` - Model checkpoint metadata
  - `analysis_history` - Analysis run history

**Query Examples**:
```sql
-- List all applications
SELECT * FROM applications;

-- Get flows for specific app
SELECT * FROM flows WHERE app_id = 1;

-- View zone assignments
SELECT n.ip_address, z.zone_name, nz.confidence
FROM nodes n
JOIN node_zone_assignments nz ON n.node_id = nz.node_id
JOIN segmentation_zones z ON nz.zone_id = z.zone_id;
```

### 2. Topology Files

#### **incremental_topology.json**
- **Location**: `outputs_final/incremental_topology.json`
- **Format**: JSON
- **Purpose**: Current state of discovered topology
- **Contents**:
```json
{
  "timestamp": "2025-10-12T23:45:00",
  "total_apps": 140,
  "apps_observed": ["XECHK", "ACDA", "DM_BLZE", ...],
  "topology": {
    "ACDA": {
      "app_type": "web",
      "security_zone": "WEB_TIER",
      "confidence": 0.85,
      "predicted_dependencies": ["APP123", "DB456"],
      "typical_protocols": ["HTTPS", "TCP"],
      "typical_ports": [443, 8080],
      "risk_level": "MEDIUM",
      "compliance_requirements": ["SOX", "PCI-DSS"]
    },
    "DM_BLZE": {
      "app_type": "datamart",
      "security_zone": "DATA_TIER",
      "confidence": 0.92,
      ...
    }
  },
  "stats": {
    "total_files_processed": 140,
    "total_flows_processed": 12500,
    "model_updates": 140,
    "zone_distribution": {
      "WEB_TIER": 18,
      "APP_TIER": 54,
      "DATA_TIER": 32,
      "CACHE_TIER": 8,
      "MESSAGING_TIER": 12,
      "MANAGEMENT_TIER": 16
    }
  }
}
```

**Use Cases**:
- Quick topology overview
- Integration with other systems
- Backup/restore topology state
- API consumption

### 3. Visualization Files

#### **network_graph_d3.html**
- **Location**: `visualizations/network_graph_d3.html`
- **Format**: HTML with embedded D3.js
- **Purpose**: Interactive network topology visualization
- **Features**:
  - Force-directed graph layout
  - Node color by security zone
  - Zoom and pan
  - Drag nodes
  - Click for node details
  - Connection lines showing traffic flows

**Open with**: Any modern web browser

#### **segmentation_mermaid.html**
- **Location**: `visualizations/segmentation_mermaid.html`
- **Format**: HTML with embedded Mermaid.js
- **Purpose**: Hierarchical segmentation diagram
- **Shows**:
  - Macro zones (EXTERNAL, DMZ, INTERNAL, RESTRICTED)
  - Micro zones (WEB_TIER, APP_TIER, DATA_TIER, etc.)
  - Zone relationships
  - Traffic flow patterns

**Open with**: Any modern web browser

#### **lucidchart_export.csv** (NEW!)
- **Location**: `visualizations/lucidchart_export.csv`
- **Format**: CSV (Lucidchart compatible)
- **Purpose**: Import into Lucidchart for professional diagrams
- **Columns**:
  - Node ID
  - Node Label
  - Node Type
  - Security Zone
  - Source
  - Target
  - Link Type
  - Link Weight

**Import to Lucidchart**:
1. Open Lucidchart
2. Go to File â†’ Import Data
3. Select "Import from CSV"
4. Upload `lucidchart_export.csv`
5. Map columns to diagram elements
6. Generate diagram

### 4. Model Checkpoints

#### **Model Files** (`.pkl` or `.pt`)
- **Location**: `models/incremental/` and `models/ensemble/`
- **Format**: Python pickle or PyTorch checkpoint
- **Purpose**: Persist trained model weights
- **Types**:
  - **GNN** (Graph Neural Network) - Application relationships
  - **RNN** (Recurrent Neural Network) - Temporal patterns
  - **CNN** (Convolutional Network) - Traffic pattern detection
  - **Attention** - Multi-head attention mechanism
  - **Meta-learner** - Combines ensemble predictions

**Use Cases**:
- Resume training without restarting
- Transfer learning
- Model versioning
- Rollback to previous versions

#### **processed_files.json**
- **Location**: `models/incremental/processed_files.json`
- **Format**: JSON
- **Purpose**: Track which files have been processed
- **Contents**:
```json
{
  "processed_files": [
    "App_Code_XECHK.csv",
    "App_Code_ACDA.csv",
    "App_Code_DM_BLZE.csv"
  ],
  "last_updated": "2025-10-12T23:45:00",
  "total_processed": 140
}
```

### 5. Log Files

#### **system_startup_*.log**
- **Location**: `logs/system_startup_YYYYMMDD_HHMMSS.log`
- **Purpose**: System initialization and startup logs
- **Contains**:
  - Dependency checks
  - Component initialization
  - Configuration validation
  - Error messages

#### **incremental_*.log**
- **Location**: `logs/incremental_YYYYMMDD_HHMMSS.log`
- **Purpose**: Incremental learning execution logs
- **Contains**:
  - File detection events
  - Processing progress
  - Model update events
  - Checkpoint saves
  - Errors and warnings

#### **web_app_*.log**
- **Location**: `logs/web_app_YYYYMMDD_HHMMSS.log`
- **Purpose**: Web application logs
- **Contains**:
  - HTTP requests
  - API calls
  - User actions
  - Server errors

### 6. Web Application (Live)

When running `python start_system.py --web`:

#### **Web Dashboard**
- **URL**: `http://localhost:5000/`
- **Features**:
  - Total applications count
  - Zone distribution chart
  - Confidence scores
  - Recent activity

#### **Topology View**
- **URL**: `http://localhost:5000/topology`
- **Features**:
  - Interactive D3.js graph
  - Filter by zone
  - Search applications
  - Export visualization

#### **Applications List**
- **URL**: `http://localhost:5000/applications`
- **Features**:
  - List all applications
  - Security zones
  - Dependencies
  - Risk scores

#### **API Endpoints**
- **Base URL**: `http://localhost:5000/api/`
- **Endpoints**:
  - `/api/applications` - Get all applications
  - `/api/topology` - Get topology data
  - `/api/zones` - Get security zones
  - `/api/stats` - Get statistics
  - `/api/export/topology` - Export topology JSON
  - `/api/export/lucidchart` - Export Lucidchart CSV

---

## Output Formats by Use Case

### For Presentation
- **network_graph_d3.html** - Interactive demo
- **segmentation_mermaid.html** - Architecture overview
- **lucidchart_export.csv** - Professional diagrams

### For Analysis
- **network_analysis.db** - SQL queries
- **incremental_topology.json** - Programmatic access
- **Log files** - Troubleshooting

### For Integration
- **API endpoints** - Real-time data access
- **JSON files** - System integration
- **CSV export** - Excel, Lucidchart, etc.

### For Backup
- **network_analysis.db** - Full data backup
- **Model checkpoints** - Trained models
- **processed_files.json** - Processing state

---

## Viewing Outputs

### View Visualizations
```bash
# Open in default browser
start visualizations/network_graph_d3.html            # Windows
open visualizations/network_graph_d3.html             # macOS
xdg-open visualizations/network_graph_d3.html         # Linux
```

### Query Database
```bash
# SQLite
sqlite3 outputs_final/network_analysis.db

# PostgreSQL
psql -U postgres -d network_analysis
```

### Read JSON Files
```bash
# Pretty print
cat outputs_final/incremental_topology.json | python -m json.tool

# Or use jq
cat outputs_final/incremental_topology.json | jq '.topology'
```

### View Logs
```bash
# Tail latest log
tail -f logs/incremental_*.log

# Search for errors
grep -i error logs/*.log
```

---

## Exporting Outputs

### Export to CSV
```python
# Python script to export topology to CSV
import json
import csv

with open('outputs_final/incremental_topology.json') as f:
    data = json.load(f)

with open('topology_export.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['App ID', 'Zone', 'Type', 'Confidence', 'Risk'])

    for app_id, app_data in data['topology'].items():
        writer.writerow([
            app_id,
            app_data['security_zone'],
            app_data['app_type'],
            app_data['confidence'],
            app_data['risk_level']
        ])
```

### Export to Excel
```python
import pandas as pd
import json

with open('outputs_final/incremental_topology.json') as f:
    data = json.load(f)

df = pd.DataFrame.from_dict(data['topology'], orient='index')
df.to_excel('topology_export.xlsx')
```

---

## Automatic Cleanup

### Old Logs
The system can automatically clean up old logs:
```bash
# Keep last 30 days
find logs/ -name "*.log" -mtime +30 -delete
```

### Old Model Checkpoints
Keep only recent checkpoints:
```bash
# Keep last 10 checkpoints per model type
ls -t models/ensemble/gnn_*.pkl | tail -n +11 | xargs rm
```

---

## Output File Sizes (Estimated)

| File | Typical Size | Notes |
|------|-------------|-------|
| network_analysis.db | 50-500 MB | Depends on # of flows |
| incremental_topology.json | 1-10 MB | Depends on # of apps |
| Model checkpoints | 10-100 MB each | PyTorch models larger |
| Log files | 1-50 MB | Per session |
| Visualizations | <1 MB each | HTML files |
| CSV exports | <5 MB | Depends on data |

---

## Best Practices

1. **Regular Backups**: Backup `network_analysis.db` and model checkpoints
2. **Log Rotation**: Archive old logs periodically
3. **Export for Sharing**: Use JSON or CSV exports for sharing
4. **Version Control**: Keep model checkpoints versioned
5. **Documentation**: Update this guide as outputs change

---

**Questions?** Check the main documentation or run `python start_system.py --help`
